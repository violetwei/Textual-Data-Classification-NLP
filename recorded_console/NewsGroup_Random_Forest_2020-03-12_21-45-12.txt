/Users/violetwei/anaconda3/bin/python /Users/violetwei/Desktop/Comp551-Group58/NewsGroup_RandomForest.py
/Users/violetwei/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.
  UserWarning)

Vectorized all data shape:  (18846, 20000)

Vectorized training data shape:  (11314, 20000)

Vectorized training data shape:  (7532, 20000)
model fitting started
Starting model Prediction

NewsGroup Random Forest Model Classification Accuracy Score: 0.5840414232607541

Classification Report:               precision    recall  f1-score   support

           0       0.41      0.29      0.34       319
           1       0.51      0.58      0.54       389
           2       0.53      0.60      0.57       394
           3       0.57      0.55      0.56       392
           4       0.64      0.62      0.63       385
           5       0.70      0.62      0.66       395
           6       0.76      0.74      0.75       390
           7       0.41      0.65      0.50       396
           8       0.59      0.64      0.61       398
           9       0.58      0.69      0.63       397
          10       0.74      0.79      0.76       399
          11       0.75      0.62      0.68       396
          12       0.44      0.42      0.43       393
          13       0.64      0.58      0.61       396
          14       0.63      0.63      0.63       394
          15       0.54      0.74      0.62       398
          16       0.52      0.59      0.55       364
          17       0.83      0.66      0.74       376
          18       0.46      0.31      0.37       310
          19       0.29      0.04      0.07       251

    accuracy                           0.58      7532
   macro avg       0.58      0.57      0.56      7532
weighted avg       0.58      0.58      0.58      7532

NewsGroup Random Forest Model Confusion Matrix: 
 [[ 93   7   1   0   0   1   5  19  10   9   8   5   5   9  17 100   9   7
    9   5]
 [  1 227  41  12  13  26   4  13   9   7   1   5  11   3  10   1   2   0
    3   0]
 [  3  28 238  32  17  15   0  16   4   9   3   2   3   8   9   0   3   2
    2   0]
 [  1  23  41 216  24  10  12  14   3   5   1   2  33   1   4   0   1   0
    1   0]
 [  1  11  11  38 237   4  11  23   4   8   0   3  19   6   6   0   0   2
    0   1]
 [  1  31  52   8   6 243   2   8   7   4   4   7   8   1   6   0   1   3
    3   0]
 [  1  10   4  13  12   4 290  18  10   4   1   1   9   1   6   1   4   0
    1   0]
 [  6   9   6   4   8   3  11 259  31  10   1   3  21   5   5   2   7   1
    3   1]
 [  6   3   2   4   8   1  10  39 253  15   7   1  18   4   7   4   6   4
    6   0]
 [  2   6   3   1   0   2   1  24   7 274  50   3   6   5   5   0   2   1
    5   0]
 [  2   1   1   0   3   2   0  13   6  39 316   1   1   4   1   0   2   1
    4   2]
 [  3  10   5   3   9   3   7  22   9  10   4 245  19   8   2   1  18   4
   12   2]
 [  1  27  17  32  15  15  12  38   9   7   7  15 166   9  13   1   4   1
    3   1]
 [  6  28   2   4   3   7   7  26  15   7   5   1  13 231  15   9   4   3
    9   1]
 [  8   9   4   5   6   4   4  27  15  11   4   4  17  10 249   4   3   1
    8   1]
 [ 18   6   3   2   0   2   2  17   7  10   1   2   6  10   6 295   0   3
    3   5]
 [  5   3   4   1   4   2   3  22  11  11   5  13   6   7  13  15 213   3
   20   3]
 [ 18   1   4   0   2   1   2  13   8  15   2   4   3   4   7  15  14 247
   15   1]
 [ 10   3   3   1   3   0   0  13   5  12   7   6  10  24   8   7  94   5
   97   2]
 [ 39   4   3   0   3   0   1  11   9   8   1   3   3  11   9  96  24   8
    8  10]]

HYPERPARAMETRE TUNING
Fitting 3 folds for each of 6 candidates, totalling 18 fits
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 91.7min finished
>>>>> Optimized params
{'criterion': 'gini', 'n_estimators': 1000}
>>>>>> Display the top results of grid search cv
   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score
2     830.095016     13.607187  ...        0.007946                1
1     269.074891      0.919229  ...        0.007780                2
0      81.201656      1.751386  ...        0.003753                3
5     438.689697      3.540036  ...        0.009010                4
4     138.843544      4.192704  ...        0.008115                5

[5 rows x 13 columns]
Using our training-dataset optimized Random Forest model on the testing dataset for evaluating
score = 0.611657

Process finished with exit code 0
