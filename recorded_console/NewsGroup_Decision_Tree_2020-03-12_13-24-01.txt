$ python NewsGroup_DecisionTree.py
C:\Program Files\Python36\lib\site-packages\sklearn\feature_extraction\text.py:1817: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.
  UserWarning)
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 23.1min finished

Vectorized all data shape:  (18846, 20000)

Vectorized training data shape:  (11314, 20000)

Vectorized training data shape:  (7532, 20000)
model fitting started
Starting model Prediction

NewsGroup Decision Tree Model Classification Accuracy Score: 0.40188528943175783

Classification Report:               precision    recall  f1-score   support

           0       0.24      0.20      0.22       319
           1       0.37      0.41      0.39       389
           2       0.39      0.39      0.39       394
           3       0.35      0.33      0.34       392
           4       0.45      0.44      0.44       385
           5       0.47      0.45      0.46       395
           6       0.56      0.57      0.56       390
           7       0.28      0.45      0.35       396
           8       0.55      0.51      0.53       398
           9       0.40      0.37      0.38       397
          10       0.58      0.58      0.58       399
          11       0.55      0.43      0.48       396
          12       0.27      0.25      0.26       393
          13       0.42      0.37      0.39       396
          14       0.46      0.45      0.46       394
          15       0.46      0.44      0.45       398
          16       0.33      0.36      0.34       364
          17       0.53      0.50      0.52       376
          18       0.20      0.23      0.21       310
          19       0.13      0.14      0.13       251

    accuracy                           0.40      7532
   macro avg       0.40      0.39      0.39      7532
weighted avg       0.41      0.40      0.40      7532

NewsGroup Decision Tree Model Confusion Matrix:
 [[ 65   8   5  10   1   9   3  18   9   8   8   8   5  12  13  45  15  23
   14  40]
 [  3 160  29  12  22  43   9  15   4  15   1   5  14  13  19   1   7   7
    4   6]
 [  3  33 153  38  19  42  12  24   7   6   3   7   4   9   7   3   7   6
    8   3]
 [  4  37  35 131  29  15  26  19   7   5   3   9  37   8   8   0   9   2
    3   5]
 [  7  26  15  31 168   4  18  23   6   3   4   8  23  12  15   2   3   2
    6   9]
 [  6  43  41  18  10 178   4  28   4   3   1   7  11   8  11   3   5   3
    6   5]
 [  2  16   9  17  24   7 223  23  14   5   8   2  17   4   5   3   4   4
    3   0]
 [  5  10   8  14   8  11  23 180  30  10   8   7  26   7  11   3  12   5
   10   8]
 [  6   9   5   8   9   5  16  44 203  11   6   1   8   6   9   5  10  13
   10  14]
 [ 10   5   2   7   8   6   6  29  16 145  79   5   6  10   7   8  11  16
   15   6]
 [  8   2   4   2   1   1   7  19   6  52 230   5  17   6  10   3   6   4
    8   8]
 [  9   6   4  10  12   8   6  31  10   6   0 172  23   9  15   8  24  10
   23  10]
 [ 13  15  24  24  24  15  18  33  14   9  11  19  98  14  14   6  14   6
   13   9]
 [ 16  22  12  18  13   9   6  31   9  15   4  12  19 145  11   6  12  11
   15  10]
 [ 10  10  11   8   4   9  10  31   5  16   6  10  16  17 178   8  14   9
   18   4]
 [ 34  10   5   2   6   4   5  22   4   7   7   6   8   9   9 175   3  14
   24  44]
 [ 15   2   9   8   4   4   3  28   7  15   3  13   9  17  15  16 130   9
   36  21]
 [ 13   4   2   4   7   3   1  15   2   9   5   6   4  16   7  22  19 189
   35  13]
 [ 10   7  10   7   5   4   1  16   5   6   7   9  17  20  14   9  70  11
   70  12]
 [ 32   3   5   1   3   4   4  13   8  15   5   4   6   5   5  56  16  11
   21  34]]

HYPERPARAMETRE TUNING
Fitting 3 folds for each of 9 candidates, totalling 27 fits
>>>>> Optimized params
{'max_depth': None, 'min_samples_split': 100}
>>>>>> Display the top results of grid search cv
   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score
7     111.586170      7.822130  ...        0.005589                1
8     103.003513      3.840258  ...        0.006392                2
6     108.021463      6.308492  ...        0.004856                3
4      44.304497      1.747323  ...        0.011252                4
3      39.484722      2.057313  ...        0.009795                5

[5 rows x 13 columns]
Using our training-dataset optimized decision tree model on the testing dataset for evaluating
score = 0.428970
